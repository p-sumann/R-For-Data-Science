---
title: "**Project 2**"
author: "**Suman Paudel**"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    
    highlight: pygments
    latex_engine: xelatex
    keep_tex: true
    extra_dependencies:
      caption: ["labelfont={bf}"]
      hyperref: ["unicode=true", "breaklinks=true"]
      lmodern: null
knit: (function(inputFile, encoding) {
      out_dir <- "reports";
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_dir=file.path(dirname(inputFile), out_dir))})
---



# **\textcolor{magenta}{Task 1}**

#### **\textcolor{magenta}{Part 1}**
##### *Task 1*
#### **Load all of the necessary packages need for task 1.**
```{r warning=FALSE, cache=TRUE, message=FALSE}
# Load the packages
library(foreign) 
library(gt)
library(tidyverse)
library(magrittr)
```

###### Load the Data using CSV module from base R
``` {r cache=TRUE}
# load the data using Base R read.csv 
data <- read.csv("covnep_252days.csv")

summary(data$totalCases)
```

###### Since we need value as 1 instead of zero We can achieve this using \ multiple ways like ifelse or pmax or subsetting

###### **Using `ifelse`**
```{r cache=TRUE}
# using ifelse
totalCases_ifelse <- ifelse(data$totalCases < 1, 1, data$totalCases)
summary(totalCases_ifelse)
```

###### **Using `pmax`**
```{r cache=TRUE}
# using pmax
totalCases_pmax <- pmax(data$totalCases, 1)
summary(totalCases_pmax)
```

###### **Using `subsetting`**
```{r cache=TRUE}
# subsetting
totalCases_subsetting <- data$totalCases
totalCases_subsetting[totalCases_subsetting < 1] <- 1
summary(totalCases_subsetting)
```


# **\textcolor{magenta}{Task 2}**

#### **Read the .sav file using foreign library which read.spss function**  

\

###### **For q01**
```{r cache=TRUE}
# read the .sav file using read_sav function from haven
saq_data <- read.spss("SAQ8.sav",to.data.frame=TRUE)

# for q1
q01 <- saq_data$q01

# computer mathematical operations
datalevels_q01 <- levels(q01)
freq_q01 <- as.numeric(table(q01))
percent_q01 <- as.numeric(round(prop.table(freq_q01) * 100, 1))
valid_percent_q01 <- as.numeric(round(prop.table(freq_q01) * 100, 1))
cum_percent <- cumsum(percent_q01)

# Create data frame
data <- data.frame(
  Levels = datalevels_q01,
  Freq = freq_q01,
  Percent = percent_q01,
  Val_Percent = valid_percent_q01,
  Cum_Percent = cum_percent
)

head(data)
```

```{r cache=TRUE}
# final version of calculated table for q01
data <- data %>% add_row(Levels = "Total", Freq = sum(data$Freq), 
                 Percent = sum(data$Percent), 
                 Val_Percent = sum(data$Val_Percent),
                 Cum_Percent = NULL)

# aethetics table using gt
data %>% gt(rowname_col = 'Levels') %>% 
  tab_header(title = md("Statistics makes me cry")) %>% 
  cols_label(Freq = "Frequency",
             Percent = "Percent",
             Val_Percent = "Valid Percent",
             Cum_Percent = "Cumulative Percent") %>% 
  sub_missing(missing_text = "")

```  

###### **For q03**

```{r cache=TRUE}

# extract q03

q03 <- saq_data$q03
datalevels_q03 <- levels(q03)
freq_q03 <- as.numeric(table(q03))
percent_q03 <- as.numeric(round(prop.table(freq_q03) * 100, 1))
valid_percent_q03 <- as.numeric(round(prop.table(freq_q03) * 100, 1))
cum_percent_q03 <- cumsum(percent_q03)

# convert the computed values into dataframe
data_q03 <- data.frame(
  Levels = datalevels_q03,
  Freq = freq_q03,
  Percent = percent_q03,
  Val_Percent = valid_percent_q03,
  Cum_Percent = cum_percent_q03
)

head(data_q03)
```

```{r cache=TRUE}

# add row for total
data_q03 <- data_q03 %>% add_row(Levels = "Total", 
                         Freq = sum(data_q03$Freq), 
                         Percent = sum(data_q03$Percent), 
                         Val_Percent = sum(data_q03$Val_Percent),
                         Cum_Percent = NULL)

# final version of calculated table
data_q03 %>% gt(rowname_col = 'Levels') %>% 
  tab_header(title = md("Statistic makes me cry")) %>% 
  cols_label(Freq = "Frequency",
             Percent = "Percent",
             Val_Percent = "Valid Percent",
             Cum_Percent = "Cumulative Percent") %>% 
  sub_missing(missing_text = "")

```

###### **For q06**

```{r cache=TRUE}

# extract q06
q06 <- saq_data$q06

datalevels_q06 <- levels(q06)
freq_q06 <- as.numeric(table(q06))
percent_q06 <- as.numeric(round(prop.table(freq_q06) * 100, 1))
valid_percent_q06 <- as.numeric(round(prop.table(freq_q06) * 100, 1))
cum_percent_q06 <- cumsum(percent_q06)

# convert into dataframe
data_q06 <- data.frame(
  Levels = datalevels_q06,
  Freq = freq_q06,
  Percent = percent_q06,
  Val_Percent = valid_percent_q06,
  Cum_Percent = cum_percent_q06
)
```

```{r cache=TRUE}

data_q06 <- data_q06 %>% add_row(Levels = "Total", 
                         Freq = sum(data_q06$Freq), 
                         Percent = sum(data_q06$Percent), 
                         Val_Percent = sum(data_q06$Val_Percent),
                         Cum_Percent = NULL)

# final version of calculated table
data_q06 %>% gt(rowname_col = 'Levels') %>% 
  tab_header(title = md("I have little experience of computer")) %>% 
  cols_label(Freq = "Frequency",
             Percent = "Percent",
             Val_Percent = "Valid Percent",
             Cum_Percent = "Cumulative Percent") %>% 
  sub_missing(missing_text = "")
```

###### **For q08**

```{r cache=TRUE}

# for q08
q08 <- saq_data$q08

datalevels_q08 <- levels(q08)
freq_q08 <- as.numeric(table(q08))
percent_q08 <- as.numeric(round(prop.table(freq_q08) * 100, 2))
valid_percent_q08 <- as.numeric(round(prop.table(freq_q08) * 100, 2))
cum_percent_q08 <- cumsum(percent_q08)

# convert into dataframe
data_q08 <- data.frame(
  Levels = datalevels_q08,
  Freq = freq_q08,
  Percent = round(valid_percent_q08,1),
  Val_Percent = round(valid_percent_q08,1),
  Cum_Percent = round(cum_percent_q08,1)
)
```

```{r cache=TRUE}


data_q08 <- data_q08 %>% add_row(Levels = "Total", 
                         Freq = sum(data_q06$Freq), 
                         Percent = sum(data_q08$Percent), 
                         Val_Percent = sum(data_q08$Val_Percent),
                         Cum_Percent = NULL)


# final version of calculated table
data_q08 %>% gt(rowname_col = 'Levels') %>% 
  tab_header(title = md("I have never been good at mathematics")) %>% 
  cols_label(Freq = "Frequency",
             Percent = "Percent",
             Val_Percent = "Valid Percent",
             Cum_Percent = "Cumulative Percent") %>% 
  sub_missing(missing_text = "")

```

#### **Task 2** Web Scraping

###### Since covid 19 data has 2 json file I had to download it using jsonlite library with `fromJSON` module
```{r cache=TRUE}
data_1 = 'https://data.covid19india.org/v4/min/timeseries.min.json'
data_2 = 'https://data.covid19india.org/v4/min/data.min.json'
covid_data_1 <- jsonlite::fromJSON(data_1)
covid_data_2 <- jsonlite::fromJSON(data_2)
covid_data_1
covid_data_2
```

```{r cache=TRUE}
covid_1_parsed <-
  covid_data_1 %>% 
  enframe() %>% 
  unnest_wider(value) %>% 
  unnest_wider(dates) %>%
  pivot_longer(cols = !name,
               names_to = 'date',
               values_to = "value") %>% unnest_wider(value) %>%
  mutate(across(c(delta, delta7, total), ~ map(., ~ set_names(
    as_tibble(.x), paste0(cur_column(), "_", names(.))
  )))) %>%
  unnest_wider(c(delta, delta7, total))

covid_1_parsed[150:300, c("delta_confirmed","delta_recovered","delta_tested","delta7_confirmed","delta7_recovered","delta_tested")]
```
##### ** Interpretation **
This code appears to be a data transformation pipeline using the `dplyr` and `tidyr` packages in R. Let's break it down step by step:

- `covid_data_1 %>% enframe()`: This converts the `covid_data_1` data frame into a two-column data frame, where the first column is the row names and the second column is the values.

- `unnest_wider(value)`: This takes the second column (the "value" column) and expands it into individual columns.

- `unnest_wider(dates)`: This takes the "dates" column and expands it into individual columns.

- `pivot_longer(cols = !name, names_to = 'date', values_to = "value")`: This reshapes the data from a wide format to a long format, where each row represents a single observation (a date and a value).

- `unnest_wider(value)`: This takes the "value" column and expands it into individual columns.

- `mutate(across(c(delta, delta7, total), ~ map(., ~ set_names(as_tibble(.), paste0(cur_column(), "_", names(.))))))`: This applies a function to the "delta", "delta7", and "total" columns. The function creates a new tibble for each element in these columns, and renames the columns in the new tibble to include the original column name and the names of the columns in the new tibble.

- `unnest_wider(c(delta, delta7, total))`: This takes the newly created columns from the previous step and expands them into individual columns.

