---
title: "Project 2"
author: "Suman Paudel"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    highlight: tango
    latex_engine: pdflatex
    keep_tex: true
knit: (function(inputFile, encoding) {
      out_dir <- "reports";
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_dir=file.path(dirname(inputFile), out_dir))})
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r warning=FALSE, cache=TRUE, message=FALSE}
# Load the packages
library(pdftools)
library(tm)
library(magrittr)
library(tibble)
library(wordcloud)
library(Rgraphviz)
library(graph)
library(ggplot2)
```

## Including Plots

You can also embed plots, for example:

```{r cache=TRUE}
files <- list.files(pattern = "pdf$")
files
```


```{r cache=TRUE}
# load the pdf files into list
pdf_files <- lapply(files, pdf_text)
```



```{r cache=TRUE}

# create a corpus from vector source i.e from list pdf_files
corpus <- Corpus(VectorSource(unlist(pdf_files)))

# make a duplicate of the loaded corpus for future use
corpus_copy <- corpus

```


#### Preprocessing Corpus 

```{r cache=TRUE, warning=FALSE}

# convert the all texts in lower
corpus <- tm_map(corpus, tolower)

# remove punctuations
corpus <- tm_map(corpus, removePunctuation)

# remove numbers
corpus <- tm_map(corpus, removeNumbers)

my_stopwords <- c("can","may","used")
# remove stopwords from the corpus
corpus <- tm_map(corpus, removeWords, my_stopwords)

# stem the corpus
corpus <- tm_map(corpus, stemDocument)

# since values and value are same so replaced values and value
remove <- function(x) gsub("values","value",x)
corpus <-  tm_map(corpus, remove)

head(corpus)
```


#### Term Document Matrix 
```{r cache=TRUE}
# create Term Document Matrix with word lenght 1 or many
tdm <- TermDocumentMatrix(corpus, control = list((wordLenghts=c(1,Inf))))
head(tdm)
```


#### Best way to create TDM with less code
```{r cache=TRUE, warning=FALSE}
remove <- function(x) gsub("values","value",x)
corpus_copy <-  tm_map(corpus_copy, remove)
my_tdm <- TermDocumentMatrix(
  corpus_copy,
  control =
    list(
      removePunctuation = TRUE,
      stopwords = TRUE,
      tolower = TRUE,
      stemming = FALSE,
      removeNumbers = TRUE,
      bounds = list(global = c(3, Inf)),
      wordLenghts = c(1,Inf),
      removeWords = (c("can","may","used")))
)
```


#### Frequency Terms 
```{r cache=TRUE}
# finding frequency of words which is at least present 10 times
low_frequent_terms <- findFreqTerms(my_tdm, lowfreq = 10)
head(low_frequent_terms)

# finding frequency of words which is at max present 10 times
high_frequent_terms <- findFreqTerms(my_tdm, highfreq = 10)
head(high_frequent_terms)
```


#### Word Association
```{r cache=TRUE}
findAssocs(my_tdm, "mining", 0.3)
findAssocs(my_tdm, "learning", 0.35)
findAssocs(my_tdm, "classification", 0.4)
```


#### Top words in TDM
```{r cache=TRUE}
# top 10 words and their respective counts 
df <-
    my_tdm %>%
    as.matrix() %>%
    rowSums() %>%
    sort(decreasing = TRUE) %>%
    head(10) %>%
    enframe(name = "word", value = "counts")

head(df)
```


#### Bar Grahph for Top 10 word counts
```{r cache=TRUE}
# top 10 words and counts using bargraph
bargraph <- ggplot(df, aes(word, counts)) +
  geom_bar(stat = "identity", fill = "#E69F00") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Top 10 words by counts.") +
  geom_text(aes(label = counts), vjust = -0.5)
bargraph
```

```{r cache=TRUE}
mat <- as.matrix(my_tdm)
freq <- mat %>% rowSums() %>% sort(decreasing = T)

# plot word cloud
wordcloud(
  words = names(freq),
  freq = freq,
  min.freq = 300,
  max.words = 500,
  random.order = FALSE,
  colors = brewer.pal(8, "Dark2"),
  
  random.color = TRUE,
  rot.per = 0.35,
  use.r.layout = FALSE
)
```

#### Word Correlation
```{r cache=TRUE}

# correlation between top 600 frequent terms
top_600_frequent_tems <- findFreqTerms(my_tdm, lowfreq = 600)
plot(my_tdm, terms = top_600_frequent_tems, corThreshold = 0.2, weighting = T)

```

